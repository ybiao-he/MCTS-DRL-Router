{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from __future__ import division\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "\n",
    "# import state_embedding as se\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class CREnv(gym.Env):\n",
    "\n",
    "    def __init__(self, board_path=\"./board.csv\"):\n",
    "        super(CREnv, self).__init__()\n",
    "\n",
    "        self.all_directions = [(1,0), (1,1), (0,1), (-1,1), (-1,0), (-1,-1), (0,-1), (1,-1)]\n",
    "\n",
    "        self.state_shape = (6,)\n",
    "\n",
    "        self.board_path = board_path\n",
    "        n_actions = 3\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "        self.observation_space = spaces.Box(low=0, high=100, shape=self.state_shape, dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.board = np.genfromtxt(self.board_path, delimiter=',')\n",
    "\n",
    "        self.head_value = 20\n",
    "        \n",
    "        self.path_length = 0\n",
    "\n",
    "        self.connection = False\n",
    "        self.collide = False\n",
    "\n",
    "        self.obstacles = []\n",
    "\n",
    "        # parse the board and get pins of each net\n",
    "        self.nets = {}\n",
    "        for i in range(self.board.shape[0]):\n",
    "            for j in range(self.board.shape[1]):\n",
    "                if abs(self.board[i,j])>=2:\n",
    "                    net_idx = abs(self.board[i,j])\n",
    "                    if net_idx in self.nets:\n",
    "                        self.nets[net_idx].append((i,j))\n",
    "                    else:\n",
    "                        self.nets[net_idx] = [(i,j)]\n",
    "                elif self.board[i,j]==1:\n",
    "                    self.obstacles.append((i,j))\n",
    "\n",
    "        self.other_nets = copy(self.nets)\n",
    "        # initialize the action node\n",
    "        self.paths45 = dict()\n",
    "        self.pairs_idx = int(min(self.nets.keys()))\n",
    "        self.max_pair = int(max(self.nets.keys()))\n",
    "        self.head = self.nets[self.pairs_idx][0]\n",
    "        self.target = self.nets[self.pairs_idx][1:]\n",
    "        self.board[self.head] = self.head_value\n",
    "        # self.other_nets.pop(self.pairs_idx)\n",
    "\n",
    "        self.pre_head = self.find_ini_prehead()\n",
    "        self.last_node = self.head\n",
    "        self.board[self.head] = self.head_value\n",
    "\n",
    "        # self.net_model = self.train_embedding_network()\n",
    "\n",
    "        # state = self.board_embedding()\n",
    "\n",
    "        # return state\n",
    "\n",
    "    def check_direction(self, direction):\n",
    "\n",
    "        x = self.head[0] + direction[0]\n",
    "        y = self.head[1] + direction[1]\n",
    "        mid_node = np.array(self.head)+np.array(direction)/2\n",
    "        mid_node = tuple(mid_node)\n",
    "        if 0 <= x < self.board.shape[0] and 0 <= y < self.board.shape[1]:\n",
    "            if not self.paths45.get(mid_node):\n",
    "                if (x,y) in self.target:\n",
    "                    return 2\n",
    "                elif self.board[(x,y)] == 0:\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    def find_ini_prehead(self):\n",
    "\n",
    "        possible_ds = []\n",
    "        for d in self.all_directions:\n",
    "            if self.check_direction(d)>0:\n",
    "                tem_target = (self.head[0]+d[0], self.head[1]+d[1])\n",
    "                possible_ds.append(d)\n",
    "\n",
    "        if len(possible_ds)>0:\n",
    "            best_d = random.choice(possible_ds)\n",
    "        else:\n",
    "            best_d = random.choice(self.all_directions)\n",
    "\n",
    "        return (self.head[0]-best_d[0], self.head[1]-best_d[1])\n",
    "\n",
    "    # def board_embedding(self):\n",
    "        \n",
    "    #     # embed current nets\n",
    "    #     current_net_vector = current_net(self.head, self.pre_head, self.target)\n",
    "\n",
    "    #     # embed other nets\n",
    "    #     node_features, adj_mat = nets_to_graph(self.other_nets)\n",
    "    #     # print(node_features)\n",
    "    #     # print(adj_mat)\n",
    "\n",
    "    #     return current_net_vector\n",
    "\n",
    "    # def train_embedding_network(self):\n",
    "        \n",
    "    #     # train network to embed nets\n",
    "    #     from preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges\n",
    "    #     from model import GCNModelAE, GCNModelVAE\n",
    "\n",
    "    #     import time\n",
    "    #     # Settings\n",
    "    #     learning_rate = 0.01\n",
    "\n",
    "    #     features, adj_mat = nets_to_graph(self.nets)\n",
    "    #     print(features.shape)\n",
    "    #     print(adj_mat.shape)\n",
    "\n",
    "    #     adj_norm = preprocess_graph(adj_mat)\n",
    "    #     num_nodes = adj_mat.shape[0]\n",
    "\n",
    "    #     num_features = features.shape[-1]\n",
    "    #     features_nonzero = features.nnz\n",
    "\n",
    "    #     model = GCNModelVAE(num_features, num_nodes, features_nonzero)\n",
    "\n",
    "    #     pos_weight = float(adj_mat.shape[0] * adj_mat.shape[0] - adj_mat.sum()) / adj_mat.sum()\n",
    "    #     norm = adj_mat.shape[0] * adj_mat.shape[0] / float((adj_mat.shape[0] * adj_mat.shape[0] - adj_mat.sum()) * 2)\n",
    "\n",
    "    #     features = convert_sparse_matrix_to_sparse_tensor(features)\n",
    "    #     adj_norm = convert_sparse_matrix_to_sparse_tensor(adj_norm)\n",
    "    #     adj_mat = convert_sparse_matrix_to_sparse_tensor(adj_mat)\n",
    "\n",
    "    #     adj_label = tf.reshape(tf.sparse.to_dense(adj_mat, validate_indices=False), [-1])\n",
    "    #     adj_label = tf.cast(adj_label, tf.float32)\n",
    "    #     features = tf.cast(features, tf.float32)\n",
    "    #     adj_norm = tf.cast(adj_norm, tf.float32)\n",
    "\n",
    "    #     optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    #     epochs = 20\n",
    "\n",
    "    #     val_roc_score = []\n",
    "\n",
    "    #     # Iterate over epochs.\n",
    "    #     for epoch in range(epochs):\n",
    "    #         print(\"Start of epoch %d\" % (epoch,))\n",
    "    #         t = time.time()\n",
    "    #         with tf.GradientTape() as tape:\n",
    "    #             reconstructed = model([features, adj_norm])\n",
    "    #             loss = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels=adj_label, \n",
    "    #                                                                                 logits=reconstructed, \n",
    "    #                                                                                 pos_weight=pos_weight))\n",
    "            \n",
    "    #         correct_prediction = tf.math.equal(\n",
    "    #                             tf.cast(tf.math.greater_equal(tf.math.sigmoid(reconstructed), 0.5), tf.int32),\n",
    "    #                                     tf.cast(adj_label, tf.int32))\n",
    "    #         accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    #         print(\"The loss is: {}; The accuracy is: {}.\".format(loss.numpy(), accuracy.numpy()))\n",
    "            \n",
    "    #         grads = tape.gradient(loss, model.trainable_weights)\n",
    "    #         optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "    #     model.summary()\n",
    "        \n",
    "    #     model.save_weights('embedding', save_format='tf')\n",
    "    #     return model"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-11 13:04:37.219355: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print('TensorFlow:', tf.__version__)\n",
    "\n",
    "\n",
    "def mlp(hidden_sizes= (32, 64), output_size= 1, activation= 'relu', activation_output= None, kernel_initalizer= 'glorot_uniform', name= 'MLP'):\n",
    "    \"\"\"\n",
    "        MLP - Multilayer Perceptron\n",
    "        ---------------------------\n",
    "\n",
    "            Hidden Sizes = [32,32] Size of HIDDEN Layers \n",
    "            Output Size = (1) Size of OUTPUT Layer\n",
    "            Activation = RELU\n",
    "            Output Activation  = NONE\n",
    "            Kernel Initializer = glorot uniform\n",
    "            bias inintializer =  ZEROS\n",
    "\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential(name=name)\n",
    "    layer_idx = 1\n",
    "    \n",
    "    # model.add(tf.keras.layers.Dense(units=32, activation=activation, name= name+\"input\", kernel_initializer= kernel_initalizer, bias_initializer= 'zeros', input_shape=input_shape))\n",
    "\n",
    "    for h in hidden_sizes:\n",
    "        model.add(tf.keras.layers.Dense(units=h, activation=activation, name= name+str(layer_idx), kernel_initializer= kernel_initalizer, bias_initializer= 'zeros'))\n",
    "        layer_idx += 1\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(units= output_size, activation= activation_output, name= name + '_output'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def info_embedding(info_dim=[6, 4, 4, 2], embed_dim=[6,8,8,4], name=\"actor\"):\n",
    "    \"\"\"\n",
    "        info_dim contains feature dimensions of current net (6), other net (4), paths (4) and obstacles (2)\n",
    "        embed_dim contains embeded dimensions of current net, other net, paths and obstacles\n",
    "    \"\"\"\n",
    "    current_nets = tf.keras.Input(shape=(info_dim[0],), name=name+\"_current_nets\")\n",
    "\n",
    "    other_net_embed_dim = embed_dim[1]\n",
    "    other_net_name = name+\"_other_net\"\n",
    "    model_other_net = mlp(hidden_sizes=[], output_size=other_net_embed_dim, activation='relu', \n",
    "                activation_output=None, name=other_net_name, kernel_initalizer='glorot_uniform')\n",
    "\n",
    "    model_other_net.build(input_shape=(None,None,info_dim[1]))\n",
    "    model_other_net.summary()\n",
    "\n",
    "    paths_embed_dim = embed_dim[2]\n",
    "    paths_name = name+\"_paths\"\n",
    "    model_paths = mlp(hidden_sizes=[], output_size=paths_embed_dim, activation='relu', \n",
    "                activation_output=None, name=paths_name, kernel_initalizer='glorot_uniform')\n",
    "\n",
    "    model_paths.build(input_shape=(None,None,info_dim[2]))\n",
    "    model_paths.summary()\n",
    "\n",
    "    obstacles_embed_dim = embed_dim[3]\n",
    "    obstacles_name = name+\"_obstacles\"\n",
    "    model_obstacles = mlp(hidden_sizes=[], output_size=obstacles_embed_dim, activation='relu', \n",
    "                activation_output=None, name=obstacles_name, kernel_initalizer='glorot_uniform')\n",
    "\n",
    "    model_obstacles.build(input_shape=(None,None,info_dim[3]))\n",
    "    model_obstacles.summary()\n",
    "\n",
    "    aggregate_outputs = tf.keras.layers.Concatenate()([current_nets,tf.math.reduce_sum(model_other_net.output, 1),\n",
    "                                                      tf.math.reduce_sum(model_paths.output,1),\n",
    "                                                      tf.math.reduce_sum(model_obstacles.output,1)])\n",
    "\n",
    "    aggregate_inputs = [current_nets, model_other_net.input, model_paths.input, model_obstacles.input]\n",
    "\n",
    "    return aggregate_inputs, aggregate_outputs\n",
    "\n",
    "\n",
    "def simple_actor_critic(hidden_sizes=(32, 32), activation='relu', activation_output=None, \n",
    "                        kernel_initalizer='glorot_uniform', name='simple_actor_critic'):\n",
    "\n",
    "    info_dim = [6,4,4,2]\n",
    "    embed_dim = [6,8,8,4]\n",
    "\n",
    "    actor_embed_input, actor_embed_output = info_embedding(info_dim=info_dim, embed_dim=embed_dim, name='actor')\n",
    "    critic_embed_input, critic_embed_output = info_embedding(info_dim=info_dim, embed_dim=embed_dim, name='critic')\n",
    "\n",
    "    actor = mlp(hidden_sizes=hidden_sizes, output_size=4, activation=activation, \n",
    "                 activation_output=activation_output, name=\"actor\", kernel_initalizer=kernel_initalizer)\n",
    "    \n",
    "    critic = mlp(hidden_sizes= hidden_sizes, output_size= 1, activation= activation, \n",
    "                  activation_output= activation_output, name=\"actor\", kernel_initalizer= kernel_initalizer)\n",
    "\n",
    "    print('Model Summary: ' + name)\n",
    "\n",
    "    actor.build(input_shape = (None, sum(embed_dim)))\n",
    "\n",
    "    critic.build(input_shape = (None, sum(embed_dim)))\n",
    "\n",
    "    actor_out = actor(actor_embed_output)\n",
    "    critic_out = critic(critic_embed_output)\n",
    "\n",
    "    _actor = tf.keras.Model(actor_embed_input, actor_out, name=name)\n",
    "    _critic = tf.keras.Model(critic_embed_input, critic_out, name=name)\n",
    "\n",
    "    _actor.summary()\n",
    "    _critic.summary()\n",
    "\n",
    "    def forward(inp= None):\n",
    "        logits = _actor(inp['vec_obs'])\n",
    "        values = _critic(inp['vec_obs'])\n",
    "        return logits, values\n",
    "\n",
    "    return {\"forward\": forward, \"trainable_networks\": [_actor, _critic]}\n",
    "\n",
    "# model_1 = mlp(name='model-1')\n",
    "# model_2 = mlp(name='model-2')\n",
    "# model_3 = mlp(name='model-3')\n",
    "\n",
    "# model_1.build(input_shape=(None,None,4))\n",
    "# model_2.build(input_shape=(None,None,4))\n",
    "\n",
    "# model_3.build(input_shape=(None,5))\n",
    "\n",
    "# current_inputs = tf.keras.Input(shape=(3,))\n",
    "\n",
    "# x = tf.keras.layers.Concatenate()([current_inputs,tf.math.reduce_sum(model_1.output, 1),tf.math.reduce_sum(model_2.output,1)])\n",
    "\n",
    "# out = model_3(x)\n",
    "# model_1_2 = tf.keras.Model([current_inputs, model_1.input, model_2.input], out, name='model-1+2')\n",
    "\n",
    "# model_1_2.summary()\n",
    "\n",
    "\n",
    "\n",
    "# info_dim = [6,8,8,4]\n",
    "\n",
    "# embed_inputs, embed_outputs = info_embedding()\n",
    "\n",
    "# model = mlp(name='agg_model')\n",
    "# model.build(input_shape=(None,sum(info_dim)))\n",
    "\n",
    "# out = model(embed_outputs)\n",
    "# final_model = tf.keras.Model(embed_inputs, out, name='final_model')\n",
    "\n",
    "# final_model.summary()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "models = simple_actor_critic()\n",
    "\n",
    "input0 = [np.ones((6,)), np.ones((6,))]\n",
    "input1 = [np.zeros((6,4)), np.zeros((7,4))]\n",
    "input2 = [np.ones((2,4)), np.ones((3,4))]\n",
    "input3 = [np.ones((129,2)), np.ones((192,2))]\n",
    "\n",
    "vec = {\"vec_obs\":[input0, input1, input2, input3]}\n",
    "\n",
    "# value = models.get_action_logp_value(vec)\n",
    "\n",
    "value = models[\"forward\"](vec)\n",
    "print(value)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow: 2.5.0\n",
      "Model: \"actor_other_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "actor_other_net_output (Dens (None, None, 8)           40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"actor_paths\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "actor_paths_output (Dense)   (None, None, 8)           40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"actor_obstacles\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "actor_obstacles_output (Dens (None, None, 4)           12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic_other_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_other_net_output (Den (None, None, 8)           40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic_paths\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_paths_output (Dense)  (None, None, 8)           40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"critic_obstacles\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "critic_obstacles_output (Den (None, None, 4)           12        \n",
      "=================================================================\n",
      "Total params: 12\n",
      "Trainable params: 12\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Summary: simple_actor_critic\n",
      "Model: \"simple_actor_critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "actor_other_net_output_input (I [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actor_paths_output_input (Input [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actor_obstacles_output_input (I [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "actor_other_net_output (Dense)  (None, None, 8)      40          actor_other_net_output_input[0][0\n",
      "__________________________________________________________________________________________________\n",
      "actor_paths_output (Dense)      (None, None, 8)      40          actor_paths_output_input[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "actor_obstacles_output (Dense)  (None, None, 4)      12          actor_obstacles_output_input[0][0\n",
      "__________________________________________________________________________________________________\n",
      "actor_current_nets (InputLayer) [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_6 (TFOpLambd (None, 8)            0           actor_other_net_output[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_7 (TFOpLambd (None, 8)            0           actor_paths_output[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_8 (TFOpLambd (None, 4)            0           actor_obstacles_output[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 26)           0           actor_current_nets[0][0]         \n",
      "                                                                 tf.math.reduce_sum_6[0][0]       \n",
      "                                                                 tf.math.reduce_sum_7[0][0]       \n",
      "                                                                 tf.math.reduce_sum_8[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "actor (Sequential)              (None, 4)            2052        concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,144\n",
      "Trainable params: 2,144\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"simple_actor_critic\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "critic_other_net_output_input ( [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "critic_paths_output_input (Inpu [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "critic_obstacles_output_input ( [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "critic_other_net_output (Dense) (None, None, 8)      40          critic_other_net_output_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "critic_paths_output (Dense)     (None, None, 8)      40          critic_paths_output_input[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "critic_obstacles_output (Dense) (None, None, 4)      12          critic_obstacles_output_input[0][\n",
      "__________________________________________________________________________________________________\n",
      "critic_current_nets (InputLayer [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_9 (TFOpLambd (None, 8)            0           critic_other_net_output[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_10 (TFOpLamb (None, 8)            0           critic_paths_output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_11 (TFOpLamb (None, 4)            0           critic_obstacles_output[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 26)           0           critic_current_nets[0][0]        \n",
      "                                                                 tf.math.reduce_sum_9[0][0]       \n",
      "                                                                 tf.math.reduce_sum_10[0][0]      \n",
      "                                                                 tf.math.reduce_sum_11[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "actor (Sequential)              (None, 1)            1953        concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,045\n",
      "Trainable params: 2,045\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Layer simple_actor_critic expects 4 input(s), but it received 8 input tensors. Inputs received: [<tf.Tensor: shape=(6,), dtype=float64, numpy=array([1., 1., 1., 1., 1., 1.])>, <tf.Tensor: shape=(6,), dtype=float64, numpy=array([1., 1., 1., 1., 1., 1.])>, <tf.Tensor: shape=(6, 4), dtype=float64, numpy=\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])>, <tf.Tensor: shape=(7, 4), dtype=float64, numpy=\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])>, <tf.Tensor: shape=(2, 4), dtype=float64, numpy=\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.]])>, <tf.Tensor: shape=(3, 4), dtype=float64, numpy=\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])>, <tf.Tensor: shape=(129, 2), dtype=float64, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])>, <tf.Tensor: shape=(192, 2), dtype=float64, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])>]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_246165/3630880946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;31m# value = models.get_action_logp_value(vec)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"forward\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_246165/3630880946.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec_obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vec_obs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     raise ValueError('Layer ' + layer_name + ' expects ' +\n\u001b[0m\u001b[1;32m    201\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                      \u001b[0;34m'but it received '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer simple_actor_critic expects 4 input(s), but it received 8 input tensors. Inputs received: [<tf.Tensor: shape=(6,), dtype=float64, numpy=array([1., 1., 1., 1., 1., 1.])>, <tf.Tensor: shape=(6,), dtype=float64, numpy=array([1., 1., 1., 1., 1., 1.])>, <tf.Tensor: shape=(6, 4), dtype=float64, numpy=\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])>, <tf.Tensor: shape=(7, 4), dtype=float64, numpy=\narray([[0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.],\n       [0., 0., 0., 0.]])>, <tf.Tensor: shape=(2, 4), dtype=float64, numpy=\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.]])>, <tf.Tensor: shape=(3, 4), dtype=float64, numpy=\narray([[1., 1., 1., 1.],\n       [1., 1., 1., 1.],\n       [1., 1., 1., 1.]])>, <tf.Tensor: shape=(129, 2), dtype=float64, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])>, <tf.Tensor: shape=(192, 2), dtype=float64, numpy=\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])>]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# GNN-based embedding with edges input\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def current_net(head, pre_head, targets):\n",
    "\n",
    "    target_embed = np.zeros((2,))\n",
    "    tem_head = np.array(head)\n",
    "    sum_euclid_distance = 0\n",
    "    for t in targets:\n",
    "        tem_t = np.array(t)\n",
    "        sum_euclid_distance += 1/np.linalg.norm(tem_t - tem_head)\n",
    "    for t in targets:\n",
    "        tem_t = np.array(t)\n",
    "        ratio_dist = 1/np.linalg.norm(tem_t - tem_head)/sum_euclid_distance\n",
    "        target_embed += tem_t*ratio_dist\n",
    "    current_net_vector = np.array(list(head)+list(pre_head)+list(target_embed))\n",
    "\n",
    "    return current_net_vector\n",
    "\n",
    "def nets_to_edgeFeature(nets):\n",
    "\n",
    "    min_idx = int(min(nets.keys()))\n",
    "    max_idx = int(max(nets.keys()))\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for i in range(min_idx+1, max_idx+1):\n",
    "        net = nets[i]\n",
    "        edges = list(itertools.combinations(net, 2))[0]\n",
    "        edges = list(edges[0] + edges[1])\n",
    "        print(edges)\n",
    "        features.append(edges)\n",
    "    \n",
    "    return features\n",
    "\n",
    "env = CREnv(board_path=\"./board.csv\")\n",
    "env.reset()\n",
    "\n",
    "print(nets_to_edgeFeature(env.other_nets))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[7, 16, 25, 19]\n",
      "[5, 12, 28, 18]\n",
      "[12, 15, 20, 16]\n",
      "[9, 9, 27, 11]\n",
      "[10, 16, 20, 17]\n",
      "[12, 14, 20, 13]\n",
      "[[7, 16, 25, 19], [5, 12, 28, 18], [12, 15, 20, 16], [9, 9, 27, 11], [10, 16, 20, 17], [12, 14, 20, 13]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# GCN-based embedding\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import random\n",
    "\n",
    "# import state_embedding as se\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "\n",
    "def current_net(head, pre_head, targets):\n",
    "\n",
    "    target_embed = np.zeros((2,))\n",
    "    tem_head = np.array(head)\n",
    "    sum_euclid_distance = 0\n",
    "    for t in targets:\n",
    "        tem_t = np.array(t)\n",
    "        sum_euclid_distance += 1/np.linalg.norm(tem_t - tem_head)\n",
    "    for t in targets:\n",
    "        tem_t = np.array(t)\n",
    "        ratio_dist = 1/np.linalg.norm(tem_t - tem_head)/sum_euclid_distance\n",
    "        target_embed += tem_t*ratio_dist\n",
    "    current_net_vector = np.array(list(head)+list(pre_head)+list(target_embed))\n",
    "\n",
    "    return current_net_vector\n",
    "\n",
    "def nets_to_graph(nets):\n",
    "\n",
    "    min_idx = int(min(nets.keys()))\n",
    "    max_idx = int(max(nets.keys()))\n",
    "\n",
    "    features = [list(xy) for xy in nets[min_idx]]\n",
    "    num_nodes = len(nets[min_idx])\n",
    "    adj_matrix = np.ones((num_nodes, num_nodes)).tolist()\n",
    "    for i in range(min_idx+1, max_idx+1):\n",
    "        features += [list(xy) for xy in nets[i]]\n",
    "        num_nodes = len(nets[i])\n",
    "        adj_matrix = block_diag(adj_matrix, np.ones((num_nodes, num_nodes)))\n",
    "\n",
    "    features = sp.sparse.csr_matrix(features)\n",
    "    adj_matrix = sp.sparse.csr_matrix(adj_matrix)\n",
    "    return features, adj_matrix\n",
    "\n",
    "env = CREnv(board_path=\"./board.csv\")\n",
    "embedding = env.reset()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-01 13:01:18.733305: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(14, 2)\n",
      "(14, 14)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-01 13:01:20.896994: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-09-01 13:01:20.987473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:20.988309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-09-01 13:01:20.988352: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-01 13:01:21.021263: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-09-01 13:01:21.021507: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-09-01 13:01:21.035629: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-09-01 13:01:21.042723: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-09-01 13:01:21.050521: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-09-01 13:01:21.058706: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-09-01 13:01:21.060709: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-09-01 13:01:21.060921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:21.062128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:21.063956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-01 13:01:21.064669: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-01 13:01:21.066335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:21.067398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-09-01 13:01:21.067558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:21.068575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:21.070213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-09-01 13:01:21.071221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-09-01 13:01:22.504643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-09-01 13:01:22.504670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-09-01 13:01:22.504678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-09-01 13:01:22.504854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:22.505446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:22.506023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-09-01 13:01:22.506553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8723 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-09-01 13:01:22.682666: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start of epoch 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-01 13:01:23.935426: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The loss is: 1.8289093971252441; The accuracy is: 0.4285714328289032.\n",
      "Start of epoch 1\n",
      "The loss is: 1.033353567123413; The accuracy is: 0.5408163070678711.\n",
      "Start of epoch 2\n",
      "The loss is: 1.18331778049469; The accuracy is: 0.43877550959587097.\n",
      "Start of epoch 3\n",
      "The loss is: 1.2470974922180176; The accuracy is: 0.37755101919174194.\n",
      "Start of epoch 4\n",
      "The loss is: 0.9296584725379944; The accuracy is: 0.3979591727256775.\n",
      "Start of epoch 5\n",
      "The loss is: 0.8681005239486694; The accuracy is: 0.3877550959587097.\n",
      "Start of epoch 6\n",
      "The loss is: 0.7542531490325928; The accuracy is: 0.4591836631298065.\n",
      "Start of epoch 7\n",
      "The loss is: 0.5684778690338135; The accuracy is: 0.5714285969734192.\n",
      "Start of epoch 8\n",
      "The loss is: 0.6365965604782104; The accuracy is: 0.40816327929496765.\n",
      "Start of epoch 9\n",
      "The loss is: 0.591610848903656; The accuracy is: 0.4183673560619354.\n",
      "Start of epoch 10\n",
      "The loss is: 0.6306016445159912; The accuracy is: 0.44897958636283875.\n",
      "Start of epoch 11\n",
      "The loss is: 0.61833655834198; The accuracy is: 0.3877550959587097.\n",
      "Start of epoch 12\n",
      "The loss is: 0.6295281648635864; The accuracy is: 0.3163265287876129.\n",
      "Start of epoch 13\n",
      "The loss is: 0.6277474164962769; The accuracy is: 0.3265306055545807.\n",
      "Start of epoch 14\n",
      "The loss is: 0.6628220677375793; The accuracy is: 0.29591837525367737.\n",
      "Start of epoch 15\n",
      "The loss is: 0.6060757637023926; The accuracy is: 0.40816327929496765.\n",
      "Start of epoch 16\n",
      "The loss is: 0.6179364919662476; The accuracy is: 0.37755101919174194.\n",
      "Start of epoch 17\n",
      "The loss is: 0.5994413495063782; The accuracy is: 0.3877550959587097.\n",
      "Start of epoch 18\n",
      "The loss is: 0.6250038743019104; The accuracy is: 0.3979591727256775.\n",
      "Start of epoch 19\n",
      "The loss is: 0.6171759963035583; The accuracy is: 0.40816327929496765.\n",
      "Model: \"gcn_model_vae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_vae (EncoderVAE)     multiple                  1088      \n",
      "_________________________________________________________________\n",
      "inner_product_decoder (Inner multiple                  0         \n",
      "=================================================================\n",
      "Total params: 1,088\n",
      "Trainable params: 1,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import division\n",
    "\n",
    "from copy import copy\n",
    "from copy import deepcopy\n",
    "from scipy.spatial import distance\n",
    "import itertools\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "import os, random\n",
    "\n",
    "\n",
    "class CREnv(gym.Env):\n",
    "    \"\"\"\n",
    "        The env is for general routing problem on the generated circuits, \n",
    "        it has 3 candudate actions: straight, 90-degree clockwise and 90-degree counter-clockwise and allows 90-degree bend\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, board_path=\"./board.csv\"):\n",
    "        super(CREnv, self).__init__()\n",
    "\n",
    "        self.all_directions = [(1,0), (0,1), (-1,0), (0,-1)]\n",
    "\n",
    "        self.state_shape = (6,)\n",
    "\n",
    "        self.board_path = board_path\n",
    "        n_actions = 3\n",
    "        self.action_space = spaces.Discrete(n_actions)\n",
    "        self.observation_space = spaces.Box(low=0, high=30, shape=self.state_shape, dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.board = np.genfromtxt(self.board_path, delimiter=',')\n",
    "        \n",
    "        self.path_length = 0\n",
    "\n",
    "        self.connection = False\n",
    "        self.collide = False\n",
    "\n",
    "        self.obstacles = []\n",
    "\n",
    "        # parse the board and get pins of each net\n",
    "        self.nets = {}\n",
    "        for i in range(self.board.shape[0]):\n",
    "            for j in range(self.board.shape[1]):\n",
    "                if abs(self.board[i,j])>=2:\n",
    "                    net_idx = abs(self.board[i,j])\n",
    "                    if net_idx in self.nets:\n",
    "                        self.nets[net_idx].append((i,j))\n",
    "                    else:\n",
    "                        self.nets[net_idx] = [(i,j)]\n",
    "                elif self.board[i,j]==1:\n",
    "                    self.obstacles.append((i,j))\n",
    "\n",
    "        # initialize the action node and paths (empty)\n",
    "        self.paths45 = dict()\n",
    "        self.pairs_idx = int(min(self.nets.keys()))\n",
    "        self.max_pair = int(max(self.nets.keys()))\n",
    "\n",
    "        self.current_net = copy(self.nets[self.pairs_idx])\n",
    "        self.other_nets = {key: value for key, value in self.nets.items() if key > self.pairs_idx}\n",
    "        self.head = self.current_net[0]\n",
    "        self.current_net.remove(self.head)\n",
    "\n",
    "        self.pre_head = self.find_ini_prehead()\n",
    "        self.last_node = self.head\n",
    "        \n",
    "        self.current_path = [self.head]\n",
    "        self.paths = {self.pairs_idx:[]}\n",
    "\n",
    "        self.targets = self.find_targets()\n",
    "\n",
    "        state = self.extract_circuit_info()\n",
    "\n",
    "        return state\n",
    "\n",
    "    def find_targets(self):\n",
    "\n",
    "        if len(self.paths[self.pairs_idx])!=0:\n",
    "            return functools.reduce(lambda a, b: a+b, self.paths[self.pairs_idx])\n",
    "        \n",
    "        return copy(self.current_net)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        action_tmp = self.get_directions_from_action(action)\n",
    "        self.connection = False\n",
    "        self.collide = False\n",
    "        self.pre_head = self.head\n",
    "\n",
    "        self.path_length += 1\n",
    "\n",
    "        # pre-determine new action node\n",
    "        self.head = (self.head[0]+action_tmp[0], self.head[1]+action_tmp[1])\n",
    "        # check/adjust new action node and set its value\n",
    "        x = self.head[0]\n",
    "        y = self.head[1]\n",
    "\n",
    "        mid_node = (np.array(self.head)+np.array(self.pre_head))/2\n",
    "        mid_node = tuple(mid_node)\n",
    "        if 0 <= x < self.board.shape[0] and 0 <= y < self.board.shape[1]:\n",
    "            if self.paths45.get(mid_node):\n",
    "                self.collide = True\n",
    "                self.goto_new_net(False)\n",
    "            else:\n",
    "                if self.head in self.target:\n",
    "                    self.current_path.append(self.head)\n",
    "                    if self.head in self.current_net:\n",
    "                        self.current_net.remove(self.head)\n",
    "                    self.goto_new_net(True)\n",
    "                    self.paths45[mid_node] = True\n",
    "                elif self.board[self.head]!=0:\n",
    "                    self.collide = True\n",
    "                    self.goto_new_net(False)\n",
    "                else:\n",
    "                    self.current_path.append(self.head)\n",
    "                    self.board[self.pre_head] = 1\n",
    "                    self.board[self.head] = 1\n",
    "                    self.paths45[mid_node] = True\n",
    "        else:\n",
    "            self.collide = True\n",
    "            self.goto_new_net(False, out_range=True)\n",
    "\n",
    "        reward = self.getReward()\n",
    "\n",
    "        state = self.extract_circuit_info()\n",
    "\n",
    "        done = self.isTerminal()\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return state, reward, done, info\n",
    "\n",
    "    def get_directions_from_action(self, act_idx):\n",
    "\n",
    "        path_d = np.array(self.head)-np.array(self.pre_head)\n",
    "\n",
    "        d_idx = (self.all_directions.index(tuple(path_d))+act_idx-1)%len(self.all_directions)\n",
    "\n",
    "        return self.all_directions[d_idx]\n",
    "\n",
    "    def find_ini_prehead(self):\n",
    "\n",
    "        possible_ds = []\n",
    "        for d in self.all_directions:\n",
    "            if self.check_direction(d)>0:\n",
    "                tem_target = (self.head[0]+d[0], self.head[1]+d[1])\n",
    "                possible_ds.append(d)\n",
    "\n",
    "        if len(possible_ds)>0:\n",
    "            best_d = random.choice(possible_ds)\n",
    "        else:\n",
    "            best_d = random.choice(self.all_directions)\n",
    "\n",
    "        return (self.head[0]-best_d[0], self.head[1]-best_d[1])\n",
    "\n",
    "    def goto_new_net(self, connection_sign, out_range=False):\n",
    "\n",
    "        self.paths[self.pairs_idx].append(self.current_path)\n",
    "\n",
    "        self.board[self.pre_head] = 1\n",
    "        self.connection = connection_sign\n",
    "        self.last_node = self.head\n",
    "\n",
    "        if not out_range:\n",
    "            self.board[self.head] = 1\n",
    "\n",
    "        if len(self.current_net)>0:\n",
    "            self.head = self.current_net[0]\n",
    "            self.pre_head = self.find_ini_prehead()\n",
    "        elif self.pairs_idx<self.max_pair:\n",
    "            self.pairs_idx += 1\n",
    "            self.current_net = copy(self.nets[self.pairs_idx])\n",
    "            self.other_nets = {key: value for key, value in self.nets.items() if key > self.pairs_idx}\n",
    "            self.head = self.current_net[0]\n",
    "            self.current_net.remove(self.head)\n",
    "\n",
    "            self.pre_head = self.find_ini_prehead()\n",
    "            self.last_node = self.head\n",
    "            \n",
    "            self.current_path = [self.head]\n",
    "            self.paths = {self.pairs_idx:[]}\n",
    "\n",
    "            self.targets = self.find_targets()\n",
    "\n",
    "        self.board[self.head] = 1\n",
    "\n",
    "    def isTerminal(self):\n",
    "\n",
    "        if self.pairs_idx > self.max_pair:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "    def getReward(self):\n",
    "\n",
    "        if self.connection:\n",
    "            return 20\n",
    "        if self.collide:\n",
    "            left_dist = 3*np.linalg.norm(np.array(self.last_node) - np.array(self.finish[self.pairs_idx-1]))\n",
    "            # distance.cityblock(self.last_node, self.finish[self.pairs_idx-1])\n",
    "            return -left_dist/10\n",
    "\n",
    "        expand_length = np.linalg.norm(np.array(self.head) - np.array(self.pre_head)) \n",
    "        return -expand_length/10\n",
    "\n",
    "    def check_direction(self, direction):\n",
    "\n",
    "        x = self.head[0] + direction[0]\n",
    "        y = self.head[1] + direction[1]\n",
    "        mid_node = np.array(self.head)+np.array(direction)/2\n",
    "        mid_node = tuple(mid_node)\n",
    "        if 0 <= x < self.board.shape[0] and 0 <= y < self.board.shape[1]:\n",
    "            if not self.paths45.get(mid_node):\n",
    "                if (x,y) == self.finish[self.pairs_idx]:\n",
    "                    return 2\n",
    "                elif self.board[(x,y)] == 0:\n",
    "                    return 1\n",
    "        return 0\n",
    "\n",
    "    def extract_circuit_info(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    # def current_net(self):\n",
    "\n",
    "    #     target_embed = np.zeros((2,))\n",
    "    #     tem_head = np.array(self.head)\n",
    "    #     sum_euclid_distance = 0\n",
    "    #     for t in targets:\n",
    "    #         tem_t = np.array(t)\n",
    "    #         sum_euclid_distance += 1/np.linalg.norm(tem_t - tem_head)\n",
    "    #     for t in targets:\n",
    "    #         tem_t = np.array(t)\n",
    "    #         ratio_dist = 1/np.linalg.norm(tem_t - tem_head)/sum_euclid_distance\n",
    "    #         target_embed += tem_t*ratio_dist\n",
    "    #     current_net_vector = np.array(list(head)+list(pre_head)+list(target_embed))\n",
    "\n",
    "    #     return current_net_vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}